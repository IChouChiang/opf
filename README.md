# Optimal Power Flow (OPF) Educational Project

Power systems optimization and machine learning study using Python, Pyomo, PYPOWER, Gurobi, and PyTorch.

## üéØ Project Overview

Educational assignments progressing from DC Optimal Power Flow (Week 2) through ML-based prediction (Week 3) to AC Optimal Power Flow (Week 4).

**Key Technologies:** Pyomo, PYPOWER/MATPOWER, Gurobi, PyTorch, NumPy

**Environment:** `opf311` (Anaconda)

---

## üìÅ Project Structure

```
opf/
‚îú‚îÄ Week2/              # DC-OPF: linear formulation, case9
‚îú‚îÄ Week3/              # ML prediction: DCOPF ‚Üí MLP, case118
‚îÇ   ‚îú‚îÄ samples/        # Training data (chunked .npz)
‚îÇ   ‚îî‚îÄ results/        # Trained models
‚îú‚îÄ Week4/              # AC-OPF: nonlinear formulation, case39
‚îÇ   ‚îú‚îÄ ac_opf_create.py       # Pyomo AbstractModel (Cartesian voltages)
‚îÇ   ‚îú‚îÄ test.py                # Solver harness (Gurobi NonConvex)
‚îÇ   ‚îî‚îÄ case39_baseline.py     # PYPOWER runopf reference
‚îú‚îÄ .github/
‚îÇ   ‚îî‚îÄ copilot-instructions.md
‚îú‚îÄ pyrightconfig.json
‚îî‚îÄ README.md
```

---

## üöÄ Quick Start

### Environment setup
```bash
conda activate opf311
```

### Week 4 AC-OPF (Current)
Run the IEEE 39-bus AC-OPF model:
```bash
python Week4/test.py
```

Baseline comparison (PYPOWER):
```bash
python Week4/case39_baseline.py
```

---

## üìä Week 4 Highlights (AC-OPF)

### Features
- **Cartesian voltage formulation:** Variables `e[i]` (real) and `f[i]` (imag) instead of polar Vm/Va
- **Fixed quadratic objective:** Minimize Œ£(a¬∑PG¬≤ + b¬∑PG + c) with cost coefficients scaled for p.u. variables
- **Nonlinear power balance:** Bilinear constraints using admittance matrix G, B from PYPOWER's `makeYbus`
- **Voltage magnitude limits:** (Vmin)¬≤ ‚â§ e¬≤ + f¬≤ ‚â§ (Vmax)¬≤
- **Gurobi NonConvex solver:** MIQCP with spatial branching, half CPU cores, 3-minute time limit, 3% MIP gap

### Results (IEEE 39-bus)
- **Objective:** 41872.30 $/hr (vs PYPOWER 41864.18, ~0.02% difference)
- **Total generation:** 62.98 p.u., **Demand:** 62.54 p.u., **Losses:** 0.44 p.u.
- **Voltage range:** 1.010‚Äì1.052 p.u. (all within limits)
- **Solve time:** ~2 seconds (optimal within tolerance)

### Technical Notes
- Cost scaling: For PG in per-unit, use `a = c2¬∑baseMVA¬≤`, `b = c1¬∑baseMVA`, `c = c0` to preserve $/hr units
- Slack bus voltage fixed to eliminate rotational symmetry
- Generator PG/QG initialized from case data for warm start
- External 1-based bus/gen numbering in output (matches PYPOWER convention)

---

## üß© Dependencies

- `pyomo` ‚Äî optimization modeling
- `pypower` ‚Äî power flow cases and reference solver
- `gurobipy` ‚Äî nonconvex quadratic solver
- `torch` ‚Äî neural network training (Week 3)
- `numpy`, `matplotlib`

See `.github/copilot-instructions.md` for detailed architecture patterns and workflow.

---

## üìù Development Notes

- **Type checking:** `pyrightconfig.json` configured; use `# pyright: reportAttributeAccessIssue=false` in Pyomo files
- **Units:** Always convert MW/MVAr to p.u. via `baseMVA` (typically 100.0)
- **MATPOWER compatibility:** Bus/gen/branch matrices follow MATPOWER column indexing (0-based in NumPy)

---

## ‚úÖ Completed Milestones

- [x] Week 2: DC-OPF with linear constraints, PTDF analysis
- [x] Week 3: ML-based OPF prediction (MLP: P_D ‚Üí P_G), 10k samples
- [x] Week 4: AC-OPF Cartesian formulation, Gurobi nonconvex solve, PYPOWER baseline validation

---

## üìö References

- MATPOWER documentation: https://matpower.org
- Pyomo: https://www.pyomo.org
- Gurobi NonConvex QCQP: https://www.gurobi.com/documentation/

------

## üß≠ 1. The baseline situation

**Devices:**

- üñ•Ô∏è *Alyce (Windows 11)* ‚Äî main workstation, VS Code
- üíª *Chromebook (Crostini Linux)* ‚Äî lightweight remote editing (vim / Jupyter)

**Environment:**
 `opf311` (Anaconda) ‚Äî shared libs for OPF, Pyomo, Gurobi, NumPy, PyTorch, etc.

**Work pattern:**
 Weekly tasks from your tutor, sometimes connected, sometimes independent.

------

## üóÇÔ∏è 2. Recommended project layout

Here‚Äôs a versioned, sync-friendly structure you can push to GitHub safely:

```
opf/
‚îÇ
‚îú‚îÄ envs/
‚îÇ   ‚îî‚îÄ environment.yml           ‚Üê conda env spec (recreate opf311)
‚îÇ
‚îú‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ week02/
‚îÇ   ‚îÇ   ‚îî‚îÄ week02.ipynb
‚îÇ   ‚îú‚îÄ week03/
‚îÇ   ‚îÇ   ‚îî‚îÄ week03.ipynb
‚îÇ   ‚îú‚îÄ shared/
‚îÇ   ‚îÇ   ‚îî‚îÄ experiments.ipynb     ‚Üê optional common scratchpad
‚îÇ
‚îú‚îÄ src/
‚îÇ   ‚îú‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ dcopf_utils.py            ‚Üê reusable helper functions
‚îÇ   ‚îî‚îÄ ml_utils.py
‚îÇ
‚îú‚îÄ data/
‚îÇ   ‚îú‚îÄ raw/                      ‚Üê never commit heavy data; use .gitignore
‚îÇ   ‚îî‚îÄ processed/
‚îÇ
‚îú‚îÄ models/                       ‚Üê trained NN checkpoints (usually git-ignored)
‚îÇ
‚îú‚îÄ .vscode/                      ‚Üê editor settings (OK to sync)
‚îú‚îÄ .gitignore
‚îú‚îÄ pyproject.toml or pyrightconfig.json
‚îú‚îÄ README.md                     ‚Üê short intro, env usage, workflow
‚îî‚îÄ requirements.txt or environment.yml
```

üü¢ **Good habits**

- Keep each week‚Äôs notebook in its own folder, versioned in git.
- Put reusable code (plots, DCOPF solvers, data loaders) in `src/`.
- Large data or model files ‚Üí `.gitignore` (sync through Drive or Git LFS if needed).
- Use `envs/environment.yml` to reproduce your conda setup on any machine.

------

## üß© 3. About environment files

### üß± Conda (`environment.yml`)

Create it once on Alyce:

```bash
conda env export --name opf311 --no-builds > envs/environment.yml
```

Then on Chromebook:

```bash
conda env create -f envs/environment.yml
```

or update:

```bash
conda env update -f envs/environment.yml
```

This file **is safe and useful to commit** ‚Äî it only lists package names & versions, no paths.

### üßæ Alternatively: pip

If you sometimes use plain pip:

```bash
pip freeze > requirements.txt
```

But for multi-platform reproducibility, `environment.yml` is better.

------

## üåê 4. GitHub synchronization strategy

- **Push/pull workflow**

  - On Alyce: regular development, commit & push
  - On Chromebook: `git pull` to update

- **.gitignore** example:

  ```
  # ignore large or transient data
  data/raw/
  models/
  .ipynb_checkpoints/
  __pycache__/
  *.log
  ```

- Never push sensitive files: license keys, `.env` with API secrets, etc.

- Optionally create branches for bigger tasks (e.g., `feature-week5-nn`).

------

## ‚öôÔ∏è 5. VS Code + Vim consistency

- Keep `.vscode/settings.json` synced ‚Äî both machines can reuse lint/formatter rules.
- On Chromebook, lightweight editing via `vim` or `jupyter` is fine; your structure doesn‚Äôt rely on VS Code features.

------

## ‚òÅÔ∏è 6. Data & model handling

GitHub has size limits (100 MB per file, 1 GB total recommended).
 So:

- Save large simulation results or neural-network checkpoints to Google Drive or your router‚Äôs SSD (mounted via SMB/NFS).
- Store only small metadata (e.g., `metadata.json`, logs) in GitHub.

------

## üß† 7. Long-term best practices

| Goal                 | Tool / Method                            |
| -------------------- | ---------------------------------------- |
| Reproducible env     | `environment.yml` pinned versions        |
| Cross-device editing | GitHub + consistent folder names         |
| Clean code reuse     | move helper functions ‚Üí `src/`           |
| Weekly progress      | separate `weekXX` folders + README notes |
| Safe syncing         | .gitignore large files                   |
| Documentation        | Markdown readme per week if necessary    |

------

## ‚úÖ TL;DR ‚Äî Best practice summary

- Keep **one conda env (`opf311`)** shared across devices via `environment.yml`.
- Organize weekly notebooks under `notebooks/weekXX/`.
- Place reusable code in `src/`.
- Commit `.vscode/`, `.gitignore`, `environment.yml`, and `.md` docs to GitHub.
- Exclude large data/models.
- Use Drive or LFS for big outputs.
- Rebuild env on Chromebook via `conda env create -f envs/environment.yml`.

------

Would you like me to show you an **example `.gitignore` and `environment.yml`** tailored for your OPF + Pyomo + Gurobi + NN workflow? It‚Äôd fit perfectly with this structure.